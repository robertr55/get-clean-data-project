find.package("devtools")
install.packages("devtools")
find_rtools()
library(devtools)
find_rtools()
available.packages()
available.packages("KernSmooth")
available.packages("KernSmooth R")
install.packages("KernSmooth")
library(KernSmooth)
add2<-function(x,y){
x+Y
}
add2 (3,5)
add2<-function(x,y){
x+y
}
add2(3,5)
above<-function(x,n){
use<-x>n
x[use]
}
x<-1:20
above(x,12)
columnmean<-function(y){
nc<-ncol(y)
means<-numeric(nc)
for(i in 1:nc){
means[i]<-mean(y[,i])
}
means
}
columnmeans(airquality)
columnmean(airquality)
columnmean<-function(y,removeNA=TRUE){
nc<-ncol(y)
means<-numeric(nc)
for(i in 1:nc){
means[i]<-mean(y[,i],na.rm=removeNA)
}
means
}
columnmean(airquality)
install.packages("IPSUR", dependencies = TRUE)
library(IPSUR)
read(IPSUR)
q()
getwd()
ls
ls()
getwd()
crazy <- function() {
x <- 3.14
print(x)
crazier <- function() {
print(x)
x <<- 42;
print(x)
}
crazier()
print(x)
}
crazy()
list?
d
?list
library(datasets)
data(iris)
?iris
q()
set.seed(1)
rpois(5,2)
?rnorm
?set.seed
set.seed(10)
x=rbinom(10,10,0.5)
e=rnorm(10,0,20)
y=0.5+2*x+e
y
x
e
library(datasets)
Rprof()
fit <- lm(y ~ X1 + X2)
library(swirl)
ls()
rm(list=ls())
swirl()
install_from_swirl("Getting and Cleaning Data")
swirl()
mydf=read.csv(path2csv,stringsAsFactors=FALSE)
mydf=read.csv("path2csv",stringsAsFactors=FALSE)
mydf <- read.csv(path2csv,stringsAsFactors=FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran,ip_id,package,country)
5:20
select(cran,r_arch:country)
select(cran,country:r_arch)
cran
select(cran,-time)
select(cran,-(X:size))
-5:20
-(5:20)
select(cran,-(X:size))
filter(cran,package=="swirl")
filter(cran,r_version=="3.1.1",country=="US")
?Comparison
filter(cran,r_version<="3.0.2",country=="IN")
filter(cran,country=="US"|country=="IN")
filter(cran,size>100500,r_os=="linux-gnu")
is.na(c(3,5,NA,10))
!is.na(c(3,5,NA,10))
filter(cran,(r_version==!is.na())
)
filter(cran,!is.na(r_version))
cran2<-select(cran,size:ip_ip)
cran2<-select(cran,size:ip_id)
arrange(cran2,ip_id)
arrange(cran2,desc(ip_id))
arrange(cran2,package,ip_id)
arrange(cran2,country,desc(r_version),ip_id)
cran3<-select(cran,ip_id,package,size)
cran3
mutate(cran3,size_mb=size/2^20)
mutate(cran3,size_mb=size/2^20,size_gb=size_mb/2)
mutate(cran3,size_mb=size/2^20,size_gb=size_mb/2^10)
mutate(cran3,correct_size=size+1000)
summarize(cran,avg_bytes=mean(size))
?n
library(dplyr)
?n
?n_distinct
?filter
?arrange
?mutate
q()
library(dplyr)
library(tidyr)
?gather
?spread
?mutate
?unique
?rbind_list
?select
?separate
?group_by
q()
?plot
?legend
q()
page=url("http://biostat.jhsph.edu/~jleek/contact.html")
lines=readLines(page)
close(page)
lines
lines[10]
lines[20]
nchar(lines[10])
nchar(lines[20])
nchar(lines[30])
nchar(lines[100])
## setup
setwd("~/Coursera/3-Getting and Cleaning Data/Project")
library(dplyr)
## read the data files from the UCI Dataset
features <- read.table("./UCI HAR Dataset/features.txt",header=FALSE)
activities <- read.table("./UCI HAR Dataset/activity_labels.txt",header=FALSE)
test_x <- read.table("./UCI HAR Dataset/test/X_test.txt",header=FALSE)
test_y <- read.table("./UCI HAR Dataset/test/y_test.txt",header=FALSE)
test_s <- read.table("./UCI HAR Dataset/test/subject_test.txt",header=FALSE)
train_x <- read.table("./UCI HAR Dataset/train/X_train.txt",header=FALSE)
train_y <- read.table("./UCI HAR Dataset/train/y_train.txt",header=FALSE)
train_s <- read.table("./UCI HAR Dataset/train/subject_train.txt",header=FALSE)
## combine and merge test/train subjects/activities/time-frequency variables
test <- cbind(test_s,test_y,test_x)
train <- cbind(train_s,train_y,train_x)
total <- rbind(test,train)
## use make.names to strip out invalid chars in features (like the "()'s")
## substitute Time for t, and Frequency for f in column names
## substitute 1 "." for the 3 "..." that make.names uses instead of "()"
## assign new column names to merged data set columns ("total")
colname1 <- c("subject", "activity")
colname2 <- make.names(features[,2])
colname_all <- c(colname1, colname2)
colname_all <- gsub("fBody","FrequencyBody",colname_all)
colname_all <- gsub("tBody","TimeBody",colname_all)
colname_all <- gsub("tGravity","TimeGravity",colname_all)
colname_all <- gsub("\\.\\.\\.","\\.",colname_all)
colname_all <- gsub("\\.\\.","",colname_all)
colnames(total)=colname_all
## substitute activity codes with activity names
tmp <- match(total[,2],activities[,1])
total[,2] <- activities[tmp,2]
## extract only columns with "mean" or "std" in column name, plus Subject & Activity
colname_match <- c("subject","activity","mean","std")
total_ms <- total[,grep(paste(colname_match,collapse="|"),names(total))]
## sort smaller mean/std dataframe by subject, activity
total_ms <- total_ms[order(total_ms$subject,total_ms$activity),]
## summarize by subject and activity, calculate mean for each variable
total_ms %>% group_by(subject,activity) %>% summarise_each(funs(mean))
write.table(total_ms,"./ProjectTidyDataset.txt",row.name=FALSE)
f=total_ms %>% group_by(subject,activity) %>% summarise_each(funs(mean))
str(f)
final <- total_ms %>% group_by(subject,activity) %>% summarise_each(funs(mean))
write.table(final,"./ProjectTidyDataset.txt",row.name=FALSE)
str(colname_all)
str(colname2)
colname_match
